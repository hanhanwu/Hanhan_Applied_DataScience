# Prototype Toolkit

## Param Tuning
* sklearn random search, grid search
* [hyperopt][1]
* [Bayesian Optimization][2]
  * "This is a constrained global optimization package built upon bayesian inference and gaussian process, that attempts to find the maximum value of an unknown function in as few iterations as possible. This technique is particularly suited for optimization of high cost functions, situations where the balance between exploration and exploitation is important."
  * [Example for tuning CatBoost, LightGBM, XGBoost][3]
    * [Description][4]



[1]:https://github.com/hyperopt/hyperopt
[2]:https://github.com/fmfn/BayesianOptimization
[3]:https://github.com/dc-aichara/DS-ML-Public/blob/master/Medium_Files/hyp_tune.ipynb
[4]:https://medium.com/analytics-vidhya/hyperparameters-optimization-for-lightgbm-catboost-and-xgboost-regressors-using-bayesian-6e7c495947a9

