{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Production Solutions\n",
    "\n",
    "There are some simple solutions which can help production deployment a lot. I'm writting down the simple methods I am using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Discrepency\n",
    "\n",
    "One of the most painful experiences in industry is to deal with production discrepency. There will be so much technical limitation that made developers impossible to do the same thing as you did when deploy data science methods on production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1 - Minor Difference in Prediction Scores\n",
    "\n",
    "* Problem:\n",
    "  * Imagine, production team needs to develop all the features you have developed, but because of the difference between languages, floating methods and so on, there could be 1,2 features always have minor difference as your values. Because of the time limitation, they have to deploy asap. So now they are asking, what if there is minor difference in prediction score, is that ok?\n",
    "\n",
    "* Answer:\n",
    "  * First of all, check how much TP, TN, FP, FN they got, comparing with your results. Think about the cost at client side. For example, to client A, missing 1 TP means losing thousands of lives, then you have to be very very careful\n",
    "  * If the cost and evaluation results are within the range, and you have to add some taste of statistics to make everyone feel better, there is a simple solution - p-value & null hypothesis\n",
    "    * NULL Hypothesis: the 2 data sets matches to each other\n",
    "    * significance level: 0.05\n",
    "  * Besides p-vlaue to evaluate all the data,we can also use central theorem (not coding here)\n",
    "    * You bootstrap samples from production team's prediction results 200 times (at least 50 times), calculating the average performance results, if it's within the acceptable range, it's also fine\n",
    "      * bootstrap with replacement is better, so that the distribution of data in each draw won't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.65723177,   1.90538727,  18.41521631,   9.02447719,\n",
       "       -15.21266885,  19.97299201,   2.72251852,   3.41182335,\n",
       "         6.67019731,  13.47617511, -10.72565211,  13.96818358,\n",
       "         3.89353636,  14.02575626,  21.85729632,  21.7926827 ,\n",
       "         2.6002457 ,  18.40688691,   6.4166989 ,  -9.02745141,\n",
       "        -7.95107047,   1.21363351,  14.2867514 ,   3.63643092,\n",
       "         8.85765142,   5.79881301,   4.58667954,   1.00967174,\n",
       "         1.30822573,   2.11171002,   7.22736357,  -9.32048023,\n",
       "         7.91637227,   0.31435761,  -2.53493093,  14.25617772,\n",
       "        16.84338922,  -4.55928849,  12.59070561,   2.90058511,\n",
       "         6.41443868,  15.39489223,   5.46505913,  27.77947609,\n",
       "         3.38908969,  17.86041325, -10.38137827,  10.23475322,\n",
       "        16.97700844,   1.24615197,   8.25977933,  -0.6610395 ,\n",
       "        12.38203713,  11.52882222,  15.21153202,  -5.25279456,\n",
       "         5.95475657,   2.24872445, -11.43267308,  -0.79446047,\n",
       "        -8.26763163,  -1.50471404,   0.36865039,  15.2464709 ,\n",
       "         8.92772945,  14.7374497 , -10.4912838 ,  -1.12320417,\n",
       "         9.02602164,   4.92149808,  -3.68304193,   0.17880026,\n",
       "        12.6005343 ,   1.40836878,  17.42601616,   9.90307272,\n",
       "         2.67612852,   2.67800255,  -7.78131045, -10.84224262,\n",
       "         2.63670324,   8.76673598,  22.50658323,  16.95329189,\n",
       "        26.68473949,  19.31112887,   4.45890788,  19.5337517 ,\n",
       "         7.47640052, -20.68057406,   5.57627941,  15.31143271,\n",
       "        21.30336271,  13.69978547,  -0.98870539,   3.44298386,\n",
       "        13.32059517,  23.21393046,  37.04182009,  16.90929341])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "ds_data = stats.norm.rvs(loc = 5,scale = 10,size = 100)\n",
    "prod_data = stats.norm.rvs(loc = 5.1,scale = 10,size = 100)\n",
    "ds_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.58843194291888334, pvalue=0.55691302576421475)\n"
     ]
    }
   ],
   "source": [
    "print stats.ttest_ind(ds_data, prod_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, p-value is higher than significant level, so null hypothesis is correct, and you can just let production pass."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
