# Prototype Toolkit

## Param Tuning
* [Tune for Hyperparameter Tuning][5]
* [Ray - Fast for building distributed applications][6]
  * Ray is a fast and simple framework for building and running distributed applications.
  * It includes `Tune`
* sklearn random search, grid search
* [hyperopt][1]
* [Bayesian Optimization][2]
  * "This is a constrained global optimization package built upon bayesian inference and gaussian process, that attempts to find the maximum value of an unknown function in as few iterations as possible. This technique is particularly suited for optimization of high cost functions, situations where the balance between exploration and exploitation is important."
  * [Example for tuning CatBoost, LightGBM, XGBoost][3]
    * [Description][4]



[1]:https://github.com/hyperopt/hyperopt
[2]:https://github.com/fmfn/BayesianOptimization
[3]:https://github.com/dc-aichara/DS-ML-Public/blob/master/Medium_Files/hyp_tune.ipynb
[4]:https://medium.com/analytics-vidhya/hyperparameters-optimization-for-lightgbm-catboost-and-xgboost-regressors-using-bayesian-6e7c495947a9
[5]:https://ray.readthedocs.io/en/latest/tune.html
[6]:https://github.com/ray-project/ray

